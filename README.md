# 🧠 혼합 Few-Shot 프롬프팅을 통한 In-Context Learning 개선

<div align="center">
  <img src="https://github.com/user-attachments/assets/bb645e1a-62d3-4953-8aaf-9865e783afd9" alt="Prompting Illustration" width="600"/>
</div>

---

## 📌 연구 개요

본 연구는 **대규모 언어 모델의 In-Context Learning 성능을 높이기 위해**, 기존의 정답 예시만을 활용하는 프롬프팅 방식을 확장하여, **의도적으로 구성된 오답 예시를 함께 제시**하는 혼합 Few-Shot 프롬프팅 기법을 제안합니다.  
이는 학습자가 정답과 오답을 대조하여 개념을 더 깊이 이해한다는 **구성주의 학습 원리**에 기반합니다.

---

## 🧪 실험 구성

- **모델**: LLaMA3
- **데이터셋**: KoBEST (5가지 태스크)
  - 추론 중심: COPA, ReCoRD 등
  - 감정/의미 중심: NSMC, KorSTS 등

---

## 📈 주요 결과

| Task Type          | 기존 Few-Shot | 혼합 Few-Shot | 효과 |
|--------------------|---------------|----------------|------|
| 추론/판단 중심     | 낮음          | **향상**       | ✅    |
| 의미 해석/감정 분류 | 보통          | 유사/감소      | ⚠️    |

- **혼합 프롬프트**는 일부 태스크에서 성능 향상을 이끌었으나, **모든 태스크에 보편적으로 유효하지는 않음**을 확인했습니다.
- 향후, **모델 아키텍처·태스크 성격·오답 구성 비율에 따른 정밀 분석**이 필요합니다.

---

## 📚 향후 연구 방향

- 오답 예시의 구성 방식 다양화
- 오답 비중 조절에 따른 학습 효과 분석
- GPT 계열 및 multilingual 모델로 확장 실험

---


