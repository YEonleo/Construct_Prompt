[요약]

  본 연구는 대규모 언어 모델의 In-Context Learning 성능을 높이기 위해, 기존의 정답 예시만을 활용하는 프롬프팅 방식을 확장하여 의도적으로 구성된 오답 예시도 함께 제시하는 혼합 Few-Shot 프롬프팅 기법을 제안한다. 이는 학습자가 정답과 오답을 대조하며 개념을 깊이 이해한다는 구성주의 학습 원리에 기반한다.
  Llama3 모델로 KoBEST의 다섯 가지 태스크를 평가한 결과, 추론/판단 중심 태스크에서는 정오답 혼합 방식이 기존 Few-Shot 대비 성능 향상을 보였다. 그러나 의미 해석/감정 분류가 중요한 태스크에서는 오히려 성능이 떨어지거나 유사하게 나타나, 태스크 의존적 효과가 두드러졌다. 이는 혼합 프롬프트가 모든 태스크에 보편적으로 유효하지 않음을 시사하며, 향후 다양한 모델·태스크·오답 예시 구성 비율에 대한 추가 검증이 필요함을 보여준다.

![image](https://github.com/user-attachments/assets/bb645e1a-62d3-4953-8aaf-9865e783afd9)
